---
title: "ISYE6501 HW1 Fall2020"
author: ""
date: "8/24/2020"
output:
  html_document:
    df_print: paged
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
#install.packages("kknn")
```

## Questions
**Question 2.1**

_Describe a situation or problem from your job, everyday life, current events, etc., for which a classification model would be appropriate. List some (up to 5) predictors that you might use._

My situation where a classification model would be appropriate is screening potential housemates' applications for a spare room in our apartment.

The classification results would have two classes: "1" means Go for the next step, and "0" means no go. The predictors can include:

* Income: this would be a continuous predictor. The higher it is, more likely we are going to classify the person into the "1" class because we don't want a housemate who cannot afford the rent or find it a significant burden to share the rent.(while we don't want someone with an insanely high income and lucrative lifestyle either...). 

*	Credit score: this would be a continuous predictor likely to range from 500 - 800. We would like to have a housemate with relatively high credit score (>700), so we know he/she is likely to pay rent on time.

*	Work/Life schedule: this would be a binary predictor with value of "1" for those who have a regular work/life schedule and a value of "0" for those who don't. We'd like someone with a regular work schedule and is not leaving and coming back home at 12am or late at night, which would disturb other housemates living here.  

*	Pet: this would be a binary predictor with "1" for those who are not allergic to pets and be kind to pets, and "1" for those who are either allergic or tend not to care much about pets. We have a cute kitty with us, so we'd like a housemate who is not allergic to cat, and ideally be nice and kind to our pet.

*	Smoking habits: this would also be a binary predictor with "0" for those who don't smoke quite a lot and "1" for those with a long-term smoking habit. No indoor smoking is permitted within our building, so we'd like to find someone who doesn't smoke a lot.


**Question 2.2**

_1.Using the support vector machine function ksvm contained in the R package kernlab, find a good classifier for this data. Show the equation of your classifier, and how well it classifies the data points in the full data set.  (Don’t worry about test/validation data yet; we’ll cover that topic soon.)_

First load the data and take a look at it:
```{r }
data <- read.delim("credit_card_data-headers.txt")
#see some basic characteristics of the data
dim(data)
str(data)
summary(data)
#colnames(data)
#the top rows of the data
head(data)

```
The response variable here is the last column R1, which is in a binary format.

Now, using the code given in the assignment, the ksvm model with C = 100, kernel as "vanilladot" and variables scaled is created below:
```{r cars}
library(kernlab)
#use set seed to make the results reproducible
set.seed(1)

model <- ksvm(as.matrix(data[,1:10]),as.factor(data[,11]),type="C-svc",kernel="vanilladot",C=100,scaled=TRUE)
```
Calculate the coefficients and the intercept, take a look:
```{r}
# calculate a1...am
a <- colSums(model@xmatrix[[1]] * model@coef[[1]])
a
#calculate a0
a0 <- model@b
a0

#see what the model predicts
pred <- predict(model,data[,1:10])
pred
sum(pred == data[,11]) / nrow(data)

#alternatively:
#sum(predict(model,data[,1:10]) == data[,11]) / nrow(data)
```
Now, this ksvm model with a C value of 100 reaches an accuracy rate of 0.8639144 - not a too bad value. However, to find the best C value, let's test with several C with different magnitudes:

```{r}
C_val <- c(1,10,100,1000,10000,100000,1000000,10000000,100000000,1000000000,10000000000,100000000000,1000000000000)
```
Let's loop through these C values:
```{r}
modelfits <- vector(length(C_val), mode = "list")
rate <- vector(length(C_val), mode = "list")

for (i in seq_along(C_val)){
  modelfits[[i]] <- ksvm(as.matrix(data[,1:10]),as.factor(data[,11]),type="C-svc",kernel="vanilladot",C=C_val[[i]],scaled=TRUE)
  rate[[i]] <- sum(predict(modelfits[[i]],data[,1:10]) == data[,11]) / nrow(data)
}

#print accuracy rates by C values
for (i in seq_along(C_val)){
  #print(C_val[[i]])
  print(rate[[i]])  
}
```
Also, let's take a look at how these different Cs are performing:
```{r C_value, echo=FALSE}
plot(log10(C_val), rate)
lines(log10(C_val), rate, lwd=1.5)

```

Now, we can see that the accuracy rate are relatively higher than 85% when C is smaller than a magnitude of 6, and keeps at the same 0.8639144 for C=1, C=10, and C=100, then slightly drops from 0.8639144 (C=100) to 0.8623853 (C=1000), then slightly climb back again to 0.8639144 (C=100000). For larger C values higher than 1,000,000, the accuracy rates change drastically, with an accuracy rate of 0.4923547 when C is at the magnitude of 10, while a rate near 0.8027523 when the C is at the magnitude of 9.

Noticing that when given a very large C value(e.g. C=1e+12), the model will be forced to make very minimal errors in classifying the training data to minimize the total loss function, yet we are looking at an accuracy rate of 0.6880734, far from successful. Therefore, we can say the data we are working with is actually not linearly separable. (Reference: https://medium.com/@maurygreen/how-to-check-for-linear-separability-13c177ae5a6e)

Given the computation time becoming much longer for even bigger C beyond the magnitude of 12, let's focus on C values below 100000 first.

Let's test several "middle" values between the magnitudes:
```{r}
C_val1 <- c(0.5,5,50,500,5000,50000,500000)
modelfits1 <- vector(length(C_val1), mode = "list")
rate1 <- vector(length(C_val1), mode = "list")
for (i in seq_along(C_val1)){
  modelfits1[[i]] <- ksvm(as.matrix(data[,1:10]),as.factor(data[,11]),type="C-svc",kernel="vanilladot",C=C_val1[[i]],scaled=TRUE)
  rate1[[i]] <- sum(predict(modelfits1[[i]],data[,1:10]) == data[,11]) / nrow(data)
}
#print accuracy rates by C values
for (i in seq_along(C_val1)){
  #print(C_val1[[i]])
  print(rate1[[i]])  
}
```
```{r, echo=FALSE}
plot(log10(C_val1), rate1)
lines(log10(C_val1), rate1, lwd=1.5)
```
So seeing the plot above,the accuracy rate is seemingly diminishing with C value increases. Let's add the previous data points we got:
```{r, echo=FALSE}
plot(log10(C_val), rate)
points(log10(C_val1), rate1, type="p")
```
Seemingly, the accuracy rate stays at the highest around 0.8639144 with C values from 0 - 500, or a magnitude of 0 - 2.
One more test:
```{r}
C_val2 <- c(0.001,0.01,0.1,0.25,2.5,25,250)
modelfits2 <- vector(length(C_val2), mode = "list")
rate2 <- vector(length(C_val2), mode = "list")
for (i in seq_along(C_val2)){
  modelfits2[[i]] <- ksvm(as.matrix(data[,1:10]),as.factor(data[,11]),type="C-svc",kernel="vanilladot",C=C_val2[[i]],scaled=TRUE)
  rate2[[i]] <- sum(predict(modelfits2[[i]],data[,1:10]) == data[,11]) / nrow(data)
}
```
```{r}
#print accuracy rates by C values
for (i in seq_along(C_val2)){
  #print(C_val2[[i]])
  print(rate2[[i]])  
}

```
Plotting them as a curve:
```{r, echo=FALSE}
plot(log10(C_val2), rate2)
lines(log10(C_val2), rate2, lwd=1.5)

```
So here for a C=0.001, the accuracy rate becomes lower again. This is because that by decreasing C to a very small value, the model has a much wider margin, thus sacrificing the accuracy rate for the training data. The choice of C value is always a trade-off between the two targets: a wider margin that would help the classifier to capture the general trend of the data by staying far from either clusters; and classifying as many data points in the training data correctly as possible(accuracy rate).

Now, seemingly that for C values ranging from 0.01 to 500, the model can reach the highest accuracy rate at 0.8639144. Let's compare the prediction results by the models we've run. Then pick one of them as the optimal C value and report back our chosen classifier.

```{r}
C_val3 <- c(0.001,0.0025,0.005,0.0075,0.01,0.05,0.075,0.1,0.25,0.5,0.75,1,2.5,5,7.5,10,25,50,75,100,250,500,750,1000,2500,5000,7500,10000,25000,50000,75000,100000,250000,500000,750000,1000000)
modelfits3 <- vector(length(C_val3), mode = "list")
pred3 <-vector(length(C_val3), mode = "list")
rate3 <- vector(length(C_val3), mode = "list")
for (i in seq_along(C_val3)){
  modelfits3[[i]] <- ksvm(as.matrix(data[,1:10]),as.factor(data[,11]),type="C-svc",kernel="vanilladot",C=C_val3[[i]],scaled=TRUE)
  pred3[[i]] <- predict(modelfits3[[i]],data[,1:10])
  rate3[[i]] <- sum(pred3[[i]] == data[,11]) / nrow(data)
}
#print accuracy rates by C values
for (i in seq_along(C_val3)){
  #print(C_val3[[i]])
  print(rate3[[i]])  
}

```
Plotting them as a curve:
```{r}
plot(log10(C_val3), rate3)
lines(log10(C_val3), rate3, lwd=1.5)
```
Let's say, we can pick a C value = 10, the #16 element in our modelfits3 list, and build our classifier as:
```{r}
# calculate a1...am
a_16 <- colSums(modelfits3[[16]]@xmatrix[[1]] * modelfits3[[16]]@coef[[1]])
a_16
length(a_16)
#calculate a0
a0_16 <- modelfits3[[16]]@b
a0_16

#print the classifier
sprintf("y = %s + %s * A1 + %s * A2 + %s * A3 + %s * A8 + %s * A9 + %s * A10 + %s * A11 + %s * A12 + %s * A14 + %s * A15", a0_16, a_16[1], a_16[2], a_16[3], a_16[4], a_16[5], a_16[6], a_16[7], a_16[8], a_16[9], a_16[10])

```


_2.	You are welcome, but not required, to try other (nonlinear) kernels as well; we’re not covering them in this course, but they can sometimes be useful and might provide better predictions than vanilladot._

Try the non-linear kernel model:
This time, reduce the number of C values we test for each kernel to save some time.
1) Try the polydot kernel
```{r }
C_val4 <- c(0.001,0.005,0.01,0.05,0.1,0.5,1,5,10,50,100,500,1000,5000,10000,50000,100000)
modelfits4 <- vector(length(C_val4), mode = "list")
rate4 <- vector(length(C_val4), mode = "list")
for (i in seq_along(C_val4)){
  modelfits4[[i]] <- ksvm(as.matrix(data[,1:10]),as.factor(data[,11]),type="C-svc",kernel="polydot",C=C_val4[[i]],scaled=TRUE)
  rate4[[i]] <- sum(predict(modelfits4[[i]],data[,1:10]) == data[,11]) / nrow(data)
}
#print accuracy rates by C values
for (i in seq_along(C_val4)){
  print(C_val4[[i]])
  print(rate4[[i]])  
}
max(unlist(rate4))
which.max(unlist(rate4))
```
Therefore, with the polydot kernel, the max accuracy rate we can get is 0.8639144 with the C value of 0.005.
```{r, echo=FALSE}
plot(log10(C_val4), rate4)
lines(log10(C_val4), rate4, lwd=1.5)

```
2) Try the rbfdot(Radial Basis kernel "Gaussian") kernel:
```{r }
C_val5 <- c(0.001,0.005,0.01,0.05,0.1,0.5,1,5,10,50,100,500,1000,5000,10000,50000,100000)
modelfits5 <- vector(length(C_val5), mode = "list")
rate5 <- vector(length(C_val5), mode = "list")
for (i in seq_along(C_val5)){
  modelfits5[[i]] <- ksvm(as.matrix(data[,1:10]),as.factor(data[,11]),type="C-svc",kernel="rbfdot",C=C_val5[[i]],scaled=TRUE)
  rate5[[i]] <- sum(predict(modelfits5[[i]],data[,1:10]) == data[,11]) / nrow(data)
}
#print accuracy rates by C values
for (i in seq_along(C_val5)){
  print(C_val5[[i]])
  print(rate5[[i]])  
}
max(unlist(rate5))
which.max(unlist(rate5))
```
```{r}
plot(log10(C_val5), rate5)
lines(log10(C_val5), rate5, lwd=1.5)

```
Therefore, with the rbfdot kernel, the max accuracy rate we can get is 0.9969419 with the C value of 100000!Yet, a really big C value like this means the model is likely to overfit the data.

Finally, let's try another non-linear kernel:
3) Try the anovadot(ANOVA RBF kernel) kernel:
```{r }
C_val6 <- c(0.001,0.005,0.01,0.05,0.1,0.5,1,5,10,50,100,500,1000,5000,10000,50000,100000)
modelfits6 <- vector(length(C_val6), mode = "list")
rate6 <- vector(length(C_val6), mode = "list")
for (i in seq_along(C_val6)){
  modelfits6[[i]] <- ksvm(as.matrix(data[,1:10]),as.factor(data[,11]),type="C-svc",kernel="anovadot",C=C_val6[[i]],scaled=TRUE)
  rate6[[i]] <- sum(predict(modelfits6[[i]],data[,1:10]) == data[,11]) / nrow(data)
}
#print accuracy rates by C values
for (i in seq_along(C_val6)){
  print(C_val6[[i]])
  print(rate6[[i]])  
}
max(unlist(rate6))
which.max(unlist(rate6))
```
With the anovadot kernel, the max accuracy rate we can get is 0.9082569 with the C value of 500!
```{r, echo=FALSE}
plot(log10(C_val6), rate6)
lines(log10(C_val6), rate6, lwd=1.5)

```

_3.	Using the k-nearest-neighbors classification function kknn contained in the R kknn package, suggest a good value of k, and show how well it classifies that data points in the full data set.  Don’t forget to scale the data (scale=TRUE in kknn)._

To identify a good value of k, I developed a function to calculate the mean accuracy rate obtained by a given k value for all the possible training and one point test set combinations.(653 data points as the training set, the other 1 point as the test set) Then I looped through a wide range of possible k value using this function to identify the optimal k value.  

```{r }
library(kknn)
#head(data)
#first, let's use the default kernel "optimal" and the default distance "2"(the Euclidean distance), for a given k = x
nrow(data)
#there are 654 data points
#check the model formula and settings are correct
model_kknn_0 <- kknn(R1~., data[-300,], data[300,], k = 10, distance = 2,kernel = "optimal",scale = TRUE)

#develop the mean accuracy function
mean_accuracy = function(x){
  model_kknn <- vector(nrow(data), mode = "list")
  fit <- vector(nrow(data), mode = "list")
  for (i in 1:654){
    model_kknn[[i]] <- kknn(R1~., data[-i,], data[i,], k = x, distance = 2,kernel = "optimal",scale = TRUE)  
    #use floor function on the fitted value + 0.5, assuming that if the model predicts at 0.5, it will be classified as 1.
    fit[[i]]<- floor(fitted.values(model_kknn[[i]])+0.5)
  }
  accuracy <- sum(fit == data[,11]) / nrow(data)
  return(accuracy)
}

#test with k=10  
mean_accuracy(10)
```

```{r}
#loop through different k
#theoretically, k can range from 1 to 653, but let's test with k from 1 to 100.
#The number of neighbors used for the "optimal" kernel should be [ (2(d+4)/(d+2))^(d/(d+4)) k ], where k is the number that would be used for unweighted knn classification, i.e. kernel="rectangular". This factor (2(d+4)/(d+2))^(d/(d+4)) is between 1.2 and 2 (see Samworth (2012) for more details).
#Reference: http://www.statslab.cam.ac.uk/~rjs57/AOS1049.pdf

k_val <- c(1:100)
accuracy_set <- vector(100, mode = "list")

for (i in 1:100){
  accuracy_set[[i]] <- mean_accuracy(i)
}
```

```{r}
#plot the accuracy rate curve as k increases from 1 to 100
plot(k_val, accuracy_set)
lines(k_val, accuracy_set, lwd=1.5)

```
Therefore, as shown above, for kknn model with the "optimal" kernel, the accuracy rate increases to its highest over 0.85 when k is close to 15, and then decreases to around 0.83, then varies around 0.83 - 0.84.
```{r}
#find the max accuracy rate
max(unlist(accuracy_set))
#locate the k value for it
which.max(unlist(accuracy_set))

```
Thus, the optimal k here is 12, and the maximum accuracy the kknn model can achieve is 0.853211.

Let's test with a couple of different kernels "triangular" and "gaussian":
```{r}
mean_accuracy1 = function(x){
  model_kknn <- vector(nrow(data), mode = "list")
  fit <- vector(nrow(data), mode = "list")
  for (i in 1:654){
    model_kknn[[i]] <- kknn(R1~., data[-i,], data[i,], k = x, distance = 2,kernel = "triangular",scale = TRUE)  
    #use floor function on the fitted value + 0.5, assuming that if the model predicts at 0.5, it will be classified as 1.
    fit[[i]]<- floor(fitted.values(model_kknn[[i]])+0.5)
  }
  accuracy <- sum(fit == data[,11]) / nrow(data)
  return(accuracy)
}

k_val <- c(1:100)
accuracy_set1 <- vector(100, mode = "list")

for (i in 1:100){
  accuracy_set1[[i]] <- mean_accuracy1(i)
}
#plot the accuracy rate curve as k increases from 1 to 100
plot(k_val, accuracy_set1)
lines(k_val, accuracy_set1, lwd=1.5)

```
```{r}
#find the max accuracy rate
max(unlist(accuracy_set1))
#locate the k value for it
which.max(unlist(accuracy_set1))
```
With triangular kernel, the optimal k here is 10, and the maximum accuracy the kknn model can achieve is 0.851682, slightly lower than that of the optimal kernel.
```{r}
mean_accuracy2 = function(x){
  model_kknn <- vector(nrow(data), mode = "list")
  fit <- vector(nrow(data), mode = "list")
  for (i in 1:654){
    model_kknn[[i]] <- kknn(R1~., data[-i,], data[i,], k = x, distance = 2,kernel = "gaussian",scale = TRUE)  
    #use floor function on the fitted value + 0.5, assuming that if the model predicts at 0.5, it will be classified as 1.
    fit[[i]]<- floor(fitted.values(model_kknn[[i]])+0.5)
  }
  accuracy <- sum(fit == data[,11]) / nrow(data)
  return(accuracy)
}

k_val <- c(1:100)
accuracy_set2 <- vector(100, mode = "list")

for (i in 1:100){
  accuracy_set2[[i]] <- mean_accuracy2(i)
}
#plot the accuracy rate curve as k increases from 1 to 100
plot(k_val, accuracy_set2)
lines(k_val, accuracy_set2, lwd=1.5)

```


```{r}
#find the max accuracy rate
max(unlist(accuracy_set2))
#locate the k value for it
which.max(unlist(accuracy_set2))
```
With the gaussian kernel, the optimal k here is 8, and the maximum accuracy the kknn model can achieve is 0.8501529, lower than both of the optimal kernel and the triangular kernel.

In addition, let's also use the training kknn method to do a leave-one-out cross validation:

```{r}
#referencing a link found online:
#http://rstudio-pubs-static.s3.amazonaws.com/24844_335efcfc09954ad99c4e05d9548ed2ad.html
#https://rstudio-pubs-static.s3.amazonaws.com/349520_6c62f724297f4084abb48493c6f703a5.html
dim(data)

#Let's split the full dataset into a 2/3 as the training set, and 1/3 as the test set
654*1/3
Sample <- sample(1:654, 218)
learning <- data[-Sample, ]
testing <- data[Sample, ]

#build the train.kknn model
model_kknn_train <- train.kknn(R1~., data = learning, 
	kmax = 100, kernel = c("rectangular", "triangular", "epanechnikov", "biweight", "triweight", "cos", "inv",  "gaussian", "rank", "optimal"))
```

```{r, echo=FALSE}
plot(model_kknn_train)

```
Let's take a look at the model's report:
```{r}
model_kknn_train

```

Here, the best k is 90, with the best kernel as triweight kernel, and the min mean square error at 0.104543.
Let's see how this model classifies the data using the test set:
```{r}
#building a confusion matrix: Reference:https://cran.r-project.org/web/packages/cvms/vignettes/creating_a_confusion_matrix.html
pred <- floor(predict(model_kknn_train, testing)+0.5)
confusion_Matrix <- table(pred, testing$R1)
print(confusion_Matrix)

```
To calculate the overall accuracy rate:
```{r}
sum(pred == testing$R1)/length(testing$R1)
```
Therefore, here the train.kknn model gives a highest accuracy rate of 0.8302752, in this case not as high as the kknn model with the K=12, and using the "optimal" kernel. 